{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data as tud\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchviz import make_dot\n",
    "import tensorwatch as tw\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 转换方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "valid_dataloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_dataloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self,num_features,hidden_size,output_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_features, 20, 5, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(20)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(50)\n",
    "        self.fc1 = nn.Linear(5*5*50, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x:1 * 28 * 28\n",
    "        \n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.ReLU(x) # 20 * 28 * 28\n",
    "        x = F.max_pool2d(x, 2, 2) # 20 * 14 * 14\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.ReLU(x) # 20 * 28 * 28\n",
    "        x = F.max_pool2d(x, 2, 2) # 50 * 5 * 5\n",
    "        \n",
    "        x = x.view(-1, 5*5*50) #reshape\n",
    "        x1 = F.ReLU(self.fc1(x))\n",
    "        \n",
    "        x1 = self.dropout(x1)\n",
    "        x1 = self.fc2(x1)\n",
    "        \n",
    "        return F.log_softmax(x1, dim = 1) # log probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657220"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNet(num_features = 3,hidden_size = 500,output_size = 10)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(20, 3, 32, 32)\n",
    "model = MyNet(num_features = 3,hidden_size = 100,output_size = 10)\n",
    "with SummaryWriter(comment = 'MyNet') as w:\n",
    "    w.add_graph(model,(dummy_input,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Res_Net,self).__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        \n",
    "       \n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        \n",
    "        self.res_connect2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        \n",
    "        self.res_connect3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "        \n",
    "        self.res_connect4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        \n",
    "        x = self.layer1(x) + x\n",
    "        x = self.layer2(x) + self.res_connect2(x)\n",
    "        x = self.layer3(x) + self.res_connect3(x)\n",
    "        x = self.layer4(x) + self.res_connect4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1,512)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4737098"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Res_Net()\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(20, 3, 32, 32)\n",
    "model = Res_Net()\n",
    "with SummaryWriter(comment = 'Res_Net') as w:\n",
    "    w.add_graph(model,(dummy_input,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG_Net,self).__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,padding=1),\n",
    "            nn.Conv2d(64,64,3,padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128,128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 3,padding=1),\n",
    "            nn.Conv2d(128, 128, 1,padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3,padding=1),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.Conv2d(256, 256, 1, padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.Conv2d(512, 512, 1, padding=1),\n",
    "            nn.MaxPool2d(2, 2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(512*4*4,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(),\n",
    "            nn.Linear(1024,10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = x.view(-1,512*4*4)\n",
    "        \n",
    "        x = self.layer5(x)\n",
    "        \n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14777162"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG_Net()\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(20, 3, 32, 32)\n",
    "model = VGG_Net()\n",
    "with SummaryWriter(comment = 'Res_Net') as w:\n",
    "    w.add_graph(model,(dummy_input,))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
